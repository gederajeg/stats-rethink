---
title: "Practice note for McElreath's (2020) \"Statistical Rethinking\""
date: 2025-05-29
date-modified: now
author:
  - name:
      given: Gede Primahadi Wijaya
      family: Rajeg
    orcid: 0000-0002-2047-8621
    url: https://udayananetworking.unud.ac.id/lecturer/880-gede-primahadi-wijaya-rajeg
    affiliation:
      name: Udayana University
      department: Bachelor of English Literature, Faculty of Humanities
      ringgold: 95322
      isni: 0000000106926937
      ror: https://ror.org/035qsg823
format:
  html:
    code-fold: true
    code-summary: "Show the code"
license: "CC BY-NC-SA"
citation: true
bibliography: references.bib
---
```{r setup}
library(tidyverse)
library(rethinking)
```

# Overview

A practice note for McElreath's [-@mcelreath2020] *Statistical Rethinking*.

### 2.1.1 Counting possibilities

-   a bag with marbles

    -   4 marbles ‚úÖ

    -   2 colours: blue and white ‚úÖ

    -   QUESTION: how many marbles there are for each colour? ü§∑‚Äç‚ôÇÔ∏è

        -   **possibilities** (or "conjectures" [@mcelreath2020, 21]) of configuration of a given colour of the marbles:

            1.  all 4 marbles are white (total 4 marbles)

            2.  1 marble is blue and 3 marbles are white (total 4 marbles)

            3.  2 marbles are blue and 2 marbles are white (total 4 marbles)

            4.  3 marbles are blue and 1 marble is white (total 4 marbles)

            5.  all 4 marbles are blue (total 4 marbles)

    -   GOAL: which of those five possibilities/conjectures is most plausible, *given* "some **evidence** about the contents of the bag" [@mcelreath2020, 21, boldface mine].

        -    the "evidence": data of pulling out a sequence of three marbles, "one at a time, replacing the marble each time and shaking the bag before drawing another marble" [@mcelreath2020, 21].

            -   the "evidence": 2 blues and 1 white
            
```{r counting-of-ways-to-produce-data-from-conjecture, message = FALSE, warning = FALSE}
#| label: tbl-initial-count
#| tbl-cap: "Initial Count of The Number of Ways a Given Conjecture to Produce the Data Drawn (i.e., Blue, White, Blue marbles sequence)"

# conjecture of (i) 4 marbles consisting of (ii) blue ("Bl") and white ("Wh") colours
conjecture <- c("Wh Wh Wh Wh",
                "Bl Wh Wh Wh",
                "Bl Bl Wh Wh",
                "Bl Bl Bl Wh",
                "Bl Bl Bl Bl")
draw1 <- "Bl"
draw2 <- "Wh"
draw3 <- "Bl"

dats <- data.frame(conjecture, draw1, draw2, draw3)
dats1 <- dats |> 
  mutate(w_to_produce_draw1 = str_count(conjecture, draw1),
         w_to_produce_draw2 = str_count(conjecture, draw2),
         w_to_produce_draw3 = str_count(conjecture, draw3),
         w_to_produce_all_draws = w_to_produce_draw1 * w_to_produce_draw2 * w_to_produce_draw3)
dats1
```
### 2.1.2 Combining other information

- updating plausibilities for each conjecture in generating the data

- the first initial count in Section 2.1.3 is labelled *prior*

```{r set-prior-data-marble}
dats1_prior <- dats1 |> 
  select(conjecture,
         prior_counts = w_to_produce_all_draws)
dats1_prior
```
- new data: "Bl" marble

```{r combine-prior-and-new-data-marble}
#| label: tbl-combine-prior-with-new-count
#| tbl-cap: "Combining Prior Counts of Ways to Produce Data of Marbles Draw with the New Number of Ways to Produce the New Data"

dats1_prior |> 
  mutate(new_draw = "Bl") |> 
  mutate(w_to_produce_draw4 = str_count(conjecture, new_draw)) |> 
  relocate(new_draw, .after = conjecture) |> 
  relocate(w_to_produce_draw4, .after = new_draw) |> 
  mutate(new_w_to_produce_all_draws = prior_counts * w_to_produce_draw4) |> 
  rename(new_ways = w_to_produce_draw4,
         priors = prior_counts,
         combined_count = new_w_to_produce_all_draws)
```


### 2.1.3 From counts to probability

```{r probability-of-ways-to-produce-data}
ways <- c( 0 , # conjecture/possibility 1
           3 , # conjecture/possibility 2
           8 , # conjecture/possibility 3
           9 , # conjecture/possibility 4
           0   # conjecture/possibility 5
)
ways/sum(ways)
```

## 2.3 Components of the Model

### 2.3.1 Variables

- target of inference: 

    - *p* (the proportion of *water* on the globe)
    
    - this *p* cannot be observed
    
    - **unobserved variable** = **PARAMETER**
    
    - *p* is **un**observed, BUT, can be *inferred* from another variable, the **observed variable**
    
- observed variable:

    - counts of *water* (*W*) and *land* (*L*)
    
### 2.3.2 Definition

- given the assumptions, count all the ways the data could arise

    - for each of the possible values of the unobserved variabel, the PARAMETER (e.g., *p*), **define** the relative number (i.e., the _probability_) "that the values of each observed variable (i.e., the data) could arise." (p. 33)
    
    - for each of the PARAMETER, define **prior** plausibility of each value that the PARAMETER could take.
    
#### 2.3.2.1 Observed variable

- "each specific value of *p* corresponds to a specific **plausibility** of the data" (p. 33)

- computing the likelihood of the data of globe toss (i.e., 6 Ws in 9 tosses under any value of *p*)

```{r code-2-2-dbinom}
dbinom(x = 6, size = 9, prob = 0.5)
# the output: the relative number of ways to get 6 Ws, given *p* = 0.5
```

::: {.callout-note title = "Rethinking: A central role of likelihood"}

- assumption influential in Bayesian and non-Bayesian is "the distribution assigned to the data", that is the likelihood (p. 34)

- use **likelihood** to explain Bayesian inference, not the priors (p. 34)

:::

## 2.4. Making the model go

### 2.4.3 Grid approximation

```{r grid-approximation-2-4-3}
#| label: fig-grid-approx-plot
#| fig-cap: "Probability of water posterior distribution"

# define the grid
grid_length_out <- 20
p_grid <- seq(from = 0, to = 1, length.out = grid_length_out)

# define prior
## cf. p. 35 Overthinking for the prior as probability distribution summing up to 1
prior <- rep(x = 1, times = grid_length_out)

# compute likelihood at each value in grid
likelihood <- dbinom(x = 6, # obs. var. of 6 Ws in the nine globe tosses
                     size = 9, # nine globe tosses
                     prob = p_grid)

# compute the product of likelihood and prior = posterior
unstandardised_posterior <- likelihood * prior

# standardise the posterior to sum to 1
std_posterior <- unstandardised_posterior/sum(unstandardised_posterior)

# visualisation (Fig 2.7) ====
plot(p_grid,
     std_posterior,
     type = "b",
     xlab = "Probability of Water",
     ylab = "Posterior Probability/Plausibility")
mtext("20 points")
```

Trying [`R code 2.5`](https://github.com/rmcelreath/rethinking/blob/ac1b3b2cda83f3e14096e2d997a6e30ad109eeee/book_code_boxes.txt#L64). Cf. @fig-grid-approx-plot-different-prior.

```{r grid-approximation-fig-2-point-5}
#| label: fig-grid-approx-plot-different-prior
#| fig-cap: "Probability of water posterior distribution of different priors (Based on R code 2.5)"

prior_1 <- ifelse(p_grid < 0.5, 0, 1)
prior_2 <- exp(-5 * abs(p_grid - 0.5))
opar <- par(no.readonly = TRUE)

unstd_posterior_1 <- likelihood * prior_1
std_posterior_1 <- unstd_posterior_1/sum(unstd_posterior_1)

unstd_posterior_2 <- likelihood * prior_2
std_posterior_2 <- unstd_posterior_2/sum(unstd_posterior_2)

par(mfcol = c(1, 2))
plot(p_grid,
     std_posterior_1,
     type = "b",
     xlab = "Probability of Water",
     ylab = "Posterior Probability/Plausibility 01")
mtext("20 points")

plot(p_grid,
     std_posterior_2,
     type = "b",
     xlab = "Probability of Water",
     ylab = "Posterior Probability/Plausibility 02")
mtext("20 points")
par(opar)
```

### 2.4.4 Quadratic approximation

- Gaussian distribution (or "normal" distribution) (p. 42)

- the `quap()` function in the `rethinking` package

```{r quadratic-approximation-in-globe-tosses}
globe_quadapp <- quap(
  alist(
    
    W ~ dbinom((W + L), prob = p), # binomial likelihood
    p ~ dunif(0, 1) # uniform prior
    
  ),
  data = list(W = 6, L = 3)
)

# display summary of quadratic approximation
quad_app_summary <- rethinking::precis(globe_quadapp)
quad_app_summary
```

- `mean` = posterior mean value of *p* (i.e., `r round(quad_app_summary$mean, 2)`)

- `sd` = posterior standard deviation value of *p*

- `5.5%` and `94.5%`  = 89% percentile interval

Interpretation [@mcelreath2020, 43]:

> _Assuming the posterior is Gaussian, it is maximized at_ _`r round(quad_app_summary$mean, 2)`_*, and its standard deviation is `r round(quad_app_summary$sd, 2)`*

Comparing the analytical posterior (using the `dbeta()` function) with the quadratic approximation.

```{r compare-analytical-and-quadratic-posterior}
# analytical calc.
W <- 6
L <- 3

curve(dbeta(x, W + 1, L + 1), from = 0, to = 1, col = "royalblue")

# quadratic approximation
curve(dnorm(x, mean = quad_app_summary$mean, sd = quad_app_summary$sd),
      lty = 2, add = TRUE)
```

- exact/analytical posterior distribution in "royalblue"

- quadratic (i.e., Gaussian/Normal Distribution) approximation in dashed black line

### 2.4.5 Markov chain Monte Carlo

```{r MCMC}
n_samples <- 1000
p <- rep(NA, n_samples)
p[1] <- 0.5
W <- 6
L <- 3
for (i in 2:n_samples) {
  
  p_new <- rnorm(n = 1, mean = p[i-1], sd = 0.1)
  if (p_new < 0) p_new <- abs(p_new)
  if (p_new > 1) p_new <- 2-p_new
  q0 <- dbinom(x = W, size = W+L, prob = p[i-1])
  q1 <- dbinom(x = W, size = W+L, prob = p_new)
  p[i] <- ifelse(runif(1) < q1/q0, p_new, p[i-1])
  
}
```

- the vector `p` now contains samples from posterior distribution

- now compare with analytical posterior (with `dbeta()`)

```{r compare-MCMC-with-analytical-posterior-dbeta}
dens(x = p, xlim = c(0, 1), col = "royalblue") # the MCMC sample of posterior distribution
curve(dbeta(x, shape1 = W+1, shape2 = L+1), lty = 2, add = TRUE)
```

